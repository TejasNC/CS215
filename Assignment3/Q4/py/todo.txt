Apparantly the data has negative refractive indices as well. Do a detailed sanity check of the model.

Do residual analysis of the best models for guaging the model robustness.

In kernel regression, what are the similarities and differences that arise due to choice of different kernel functions. What are some metrics that you can use to support your findings. For example:
i. Can you show choice of bandwidth is more important than kernel selection for all kernels?
ii. How is optimal bandwidth dependent on kernel and data?
iii. Does choice of kernel significantly affect performance, if so by what margin?
and so on.

In kernel regression, the choice of the kernel function and bandwidth significantly impacts the model's performance. Here’s an analysis of the similarities and differences that arise from using different kernel functions and how these factors influence the results:

### 1. **Impact of Kernel Choice and Bandwidth:**
   - **Kernel Functions**: Kernel functions determine the shape of the weighting scheme used to fit the regression line. Common kernels include Gaussian, Epanechnikov, and Uniform kernels. While different kernels assign weights differently, the general behavior of the regression line remains similar, as long as the kernels are smooth and continuous.
   - **Bandwidth (Smoothing Parameter)**: The bandwidth is a critical parameter that controls the smoothness of the fitted line. A small bandwidth leads to overfitting (high variance), while a large bandwidth leads to underfitting (high bias). Therefore, bandwidth selection typically has a more significant impact than the choice of kernel because it directly affects the trade-off between bias and variance.

### 2. **Metrics to Support Findings:**
   To analyze the effect of different kernels and bandwidths, you can use the following metrics:
   - **Mean Squared Error (MSE)**: Measures the average squared difference between the observed and predicted values. It helps evaluate the model's overall performance.
   - **Cross-Validation Score**: Use techniques like k-fold cross-validation to assess the robustness of the kernel regression across different bandwidths and kernels.
   - **R-Squared (R²) Score**: Indicates how well the regression line fits the data. Higher values suggest better fits.
   - **Log-Likelihood**: Can be used to compare how well different models (kernel + bandwidth combinations) predict the data.

### 3. **Analysis Points:**

   **i. Choice of Bandwidth vs. Kernel Selection:**
   - **Hypothesis**: The choice of bandwidth is more critical than the specific kernel used, as long as the kernels belong to the same family of smooth functions.
   - **Evidence**: Empirical studies often show that the bandwidth parameter largely determines the degree of smoothing, which affects the trade-off between bias and variance. While different kernels may change the weight distribution slightly, the effect of bandwidth on overall performance tends to be more pronounced.
   - **Approach**: Conduct a grid search over different bandwidths for each kernel and use cross-validation to find the optimal combination. Compare the MSE across kernels using the same bandwidths to determine if there’s a significant difference.

   **ii. Optimal Bandwidth Dependency on Kernel and Data:**
   - **Observation**: Different kernels may have different optimal bandwidths due to how they weigh data points. For instance, the Gaussian kernel tends to smooth out more because of its long tails, while the Epanechnikov kernel may emphasize points closer to the center.
   - **Approach**: Optimize the bandwidth for each kernel separately using cross-validation. Assess how the optimal bandwidth varies depending on data characteristics like density, noise level, and distribution. Compare bandwidth values and corresponding performances to draw conclusions.

   **iii. Does Choice of Kernel Significantly Affect Performance?**
   - **Hypothesis**: For most practical purposes, the choice of kernel does not drastically affect performance if the bandwidth is properly tuned. However, there can be marginal differences, especially when the data distribution is non-standard.
   - **Evidence**: Evaluate the performance using MSE, R² score, and cross-validation scores for various kernels at their optimal bandwidths. If the differences in these metrics are minimal, it can be inferred that kernel choice is less significant. However, if one kernel consistently performs better, it indicates the choice of kernel can affect performance.
   - **Quantifying Margins**: Calculate the percentage difference in MSE or R² scores between the best and worst-performing kernels to quantify the impact of kernel choice.

### 4. **General Recommendations:**
   - **Kernel Selection**: Use a simple kernel like the Epanechnikov or Gaussian, as they provide robust performance. In practice, Epanechnikov is often preferred for its optimal properties in certain cases.
   - **Bandwidth Optimization**: Prioritize tuning the bandwidth parameter using techniques like cross-validation, Silverman’s rule of thumb, or plug-in estimators. Tools like grid search or gradient-based optimization can help find the best bandwidth.

### 5. **Conclusion:**
   While the choice of kernel affects how weights are assigned, the bandwidth controls the overall smoothness and, therefore, has a more substantial impact on model performance. The kernel selection can slightly influence performance based on the specific characteristics of the dataset, but careful bandwidth tuning often compensates for these differences. By using metrics like MSE and cross-validation scores, you can objectively evaluate and quantify the relative importance of kernel choice and bandwidth.